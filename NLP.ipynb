{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNGPN7UxJzNrgJUgO414YG8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DuncanPro64/Natural-language-processing/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4wwWftrZuHa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KAR1xf4VZu2U",
        "outputId": "a96d56c0-120c-4124-8dab-f04a8836c9eb"
      },
      "source": [
        "import nltk\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "text=\"A Hare was making fun of the Tortoise one day for being so slow. 'Do you ever get anywhere?' he asked with a mocking laugh. 'Yes,' replied the Tortoise, 'and I get there sooner than you think. I'll run you a race and prove it.' The Hare was much amused at the idea of running a race with the Tortoise, but for the fun of the thing he agreed. So, the Fox, who had consented to act as judge, marked the distance and started the runners off.\"\n",
        "tokenized_text = sent_tokenize(text)\n",
        "print(tokenized_text)\n",
        "tokenized_word = word_tokenize(text)\n",
        "print(tokenized_word)\n",
        "stop_words=set(stopwords.words(\"english\"))\n",
        "filtered_tokens=[]\n",
        "for w in tokenized_word:\n",
        " if w not in stop_words:\n",
        "    filtered_tokens.append(w)\n",
        "print(\"Tokenized Words:\",tokenized_word)\n",
        "print(\"Filterd Tokens:\",filtered_tokens)\n",
        "punctuations = list(string.punctuation)\n",
        "filtered_tokens2 = []\n",
        "for i in filtered_tokens:\n",
        "    if i not in punctuations:\n",
        "        filtered_tokens2.append(i)\n",
        "print(\"Filterd Tokens After Removing Punctuations:\", filtered_tokens2)\n",
        "ps = PorterStemmer()\n",
        "words = [\"Hare\" ,\"making\", \"fun\",\" Tortoise\",\" anywhere\",\" asked\",\" mocking\",\" laugh\",\" replies\",\" sooner\",\" think\",\" race\",\" prove\",\"amused\",\" idea \",\"fun\",\" thing\",\" agreed\",\" Fox\",\" consented\",\" judge\",\" marked\",\" distance \",\"started\"]\n",
        "for w in words:\n",
        "    print(w, \" : \", ps.stem(w))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print(\"hare:\", lemmatizer.lemmatize(\"hare\"))\n",
        "print(\"making:\", lemmatizer.lemmatize(\"make\"))\n",
        "print(\"fun:\", lemmatizer.lemmatize(\"fun\"))\n",
        "print(\"tortoise:\", lemmatizer.lemmatize(\"tortoise\"))\n",
        "print(\"slow:\", lemmatizer.lemmatize(\"slow\"))\n",
        "print(\"sooner:\", lemmatizer.lemmatize(\"soon\"))\n",
        "print(\"think:\", lemmatizer.lemmatize(\"think\"))\n",
        "print(\"agreed:\", lemmatizer.lemmatize(\"agree\"))\n",
        "print(\"fox:\", lemmatizer.lemmatize(\"fox\"))\n",
        "print(\"act:\",lemmatizer.lemmatize(\"act\"))\n",
        "print(\"judge:\", lemmatizer.lemmatize(\"judge\",pos=\"a\"))\n",
        "print(\"marked:\", lemmatizer.lemmatize(\"mark\"))\n",
        "print(\"distance:\", lemmatizer.lemmatize(\"distance\",))\n",
        "print(\"started:\", lemmatizer.lemmatize(\"start\",))\n",
        "print(\"runners:\", lemmatizer.lemmatize(\"run\",))\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "['A Hare was making fun of the Tortoise one day for being so slow.', \"'Do you ever get anywhere?'\", 'he asked with a mocking laugh.', \"'Yes,' replied the Tortoise, 'and I get there sooner than you think.\", \"I'll run you a race and prove it.'\", 'The Hare was much amused at the idea of running a race with the Tortoise, but for the fun of the thing he agreed.', 'So, the Fox, who had consented to act as judge, marked the distance and started the runners off.']\n",
            "['A', 'Hare', 'was', 'making', 'fun', 'of', 'the', 'Tortoise', 'one', 'day', 'for', 'being', 'so', 'slow', '.', \"'Do\", 'you', 'ever', 'get', 'anywhere', '?', \"'\", 'he', 'asked', 'with', 'a', 'mocking', 'laugh', '.', \"'Yes\", ',', \"'\", 'replied', 'the', 'Tortoise', ',', \"'and\", 'I', 'get', 'there', 'sooner', 'than', 'you', 'think', '.', 'I', \"'ll\", 'run', 'you', 'a', 'race', 'and', 'prove', 'it', '.', \"'\", 'The', 'Hare', 'was', 'much', 'amused', 'at', 'the', 'idea', 'of', 'running', 'a', 'race', 'with', 'the', 'Tortoise', ',', 'but', 'for', 'the', 'fun', 'of', 'the', 'thing', 'he', 'agreed', '.', 'So', ',', 'the', 'Fox', ',', 'who', 'had', 'consented', 'to', 'act', 'as', 'judge', ',', 'marked', 'the', 'distance', 'and', 'started', 'the', 'runners', 'off', '.']\n",
            "Tokenized Words: ['A', 'Hare', 'was', 'making', 'fun', 'of', 'the', 'Tortoise', 'one', 'day', 'for', 'being', 'so', 'slow', '.', \"'Do\", 'you', 'ever', 'get', 'anywhere', '?', \"'\", 'he', 'asked', 'with', 'a', 'mocking', 'laugh', '.', \"'Yes\", ',', \"'\", 'replied', 'the', 'Tortoise', ',', \"'and\", 'I', 'get', 'there', 'sooner', 'than', 'you', 'think', '.', 'I', \"'ll\", 'run', 'you', 'a', 'race', 'and', 'prove', 'it', '.', \"'\", 'The', 'Hare', 'was', 'much', 'amused', 'at', 'the', 'idea', 'of', 'running', 'a', 'race', 'with', 'the', 'Tortoise', ',', 'but', 'for', 'the', 'fun', 'of', 'the', 'thing', 'he', 'agreed', '.', 'So', ',', 'the', 'Fox', ',', 'who', 'had', 'consented', 'to', 'act', 'as', 'judge', ',', 'marked', 'the', 'distance', 'and', 'started', 'the', 'runners', 'off', '.']\n",
            "Filterd Tokens: ['A', 'Hare', 'making', 'fun', 'Tortoise', 'one', 'day', 'slow', '.', \"'Do\", 'ever', 'get', 'anywhere', '?', \"'\", 'asked', 'mocking', 'laugh', '.', \"'Yes\", ',', \"'\", 'replied', 'Tortoise', ',', \"'and\", 'I', 'get', 'sooner', 'think', '.', 'I', \"'ll\", 'run', 'race', 'prove', '.', \"'\", 'The', 'Hare', 'much', 'amused', 'idea', 'running', 'race', 'Tortoise', ',', 'fun', 'thing', 'agreed', '.', 'So', ',', 'Fox', ',', 'consented', 'act', 'judge', ',', 'marked', 'distance', 'started', 'runners', '.']\n",
            "Filterd Tokens After Removing Punctuations: ['A', 'Hare', 'making', 'fun', 'Tortoise', 'one', 'day', 'slow', \"'Do\", 'ever', 'get', 'anywhere', 'asked', 'mocking', 'laugh', \"'Yes\", 'replied', 'Tortoise', \"'and\", 'I', 'get', 'sooner', 'think', 'I', \"'ll\", 'run', 'race', 'prove', 'The', 'Hare', 'much', 'amused', 'idea', 'running', 'race', 'Tortoise', 'fun', 'thing', 'agreed', 'So', 'Fox', 'consented', 'act', 'judge', 'marked', 'distance', 'started', 'runners']\n",
            "Hare  :  hare\n",
            "making  :  make\n",
            "fun  :  fun\n",
            " Tortoise  :   tortois\n",
            " anywhere  :   anywher\n",
            " asked  :   ask\n",
            " mocking  :   mock\n",
            " laugh  :   laugh\n",
            " replies  :   repli\n",
            " sooner  :   sooner\n",
            " think  :   think\n",
            " race  :   race\n",
            " prove  :   prove\n",
            "amused  :  amus\n",
            " idea   :   idea \n",
            "fun  :  fun\n",
            " thing  :   thing\n",
            " agreed  :   agre\n",
            " Fox  :   fox\n",
            " consented  :   consent\n",
            " judge  :   judg\n",
            " marked  :   mark\n",
            " distance   :   distance \n",
            "started  :  start\n",
            "hare: hare\n",
            "making: make\n",
            "fun: fun\n",
            "tortoise: tortoise\n",
            "slow: slow\n",
            "sooner: soon\n",
            "think: think\n",
            "agreed: agree\n",
            "fox: fox\n",
            "act: act\n",
            "judge: judge\n",
            "marked: mark\n",
            "distance: distance\n",
            "started: start\n",
            "runners: run\n"
          ]
        }
      ]
    }
  ]
}